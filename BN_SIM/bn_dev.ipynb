{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import OrderedDict\n",
    "from pyinstrument import Profiler\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import dynml as dml\n",
    "\n",
    "np.random.seed(42)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "%matplotlib notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnfuncsfile = '_swarmout/gbmbnet_wm_raf_ck2_0/gbmbnet_wm_raf_ck2_0.txt'\n",
    "context = 'WM'\n",
    "#------------------------------------------------------------------------------------------\n",
    "assert(os.path.isfile(bnfuncsfile))\n",
    "bnfuncsdir = os.path.dirname(bnfuncsfile)\n",
    "dfsdir = bnfuncsdir + '/dfs/'\n",
    "input_to_attr_df_file = bnfuncsdir + '/input_to_attr_df.pkl'\n",
    "uniq_attr_df_file = bnfuncsdir + '/uniq_attr_df.pkl'\n",
    "\n",
    "# set inputs based on context\n",
    "# below: check phenotype column based on context\n",
    "if context == 'BP':\n",
    "    input_nodes = ['EGF', 'PDGF', 'WNT_Canonical', 'TIMP', 'DNA_Damage', 'Ephrin_B1_B2', 'Oxygen']\n",
    "elif context == 'PS':\n",
    "    input_nodes = ['EGF', 'PDGF', 'WNT_Canonical', 'TIMP', 'DNA_Damage', 'Ephrin_B1_B2']\n",
    "elif context == 'WM':\n",
    "    input_nodes = ['EGF', 'PDGF', 'WNT_Canonical', 'TIMP', 'DNA_Damage', 'Ephrin_B1_B2', 'Oxygen']\n",
    "else:\n",
    "    assert(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Biowulf Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [pd.read_pickle(dfsdir + '/' + pklfile) for pklfile in os.listdir(dfsdir) \n",
    "       if pklfile.endswith('.pkl')]\n",
    "dfmerged = pd.concat(dfs)\n",
    "dfmerged.insert(loc=0, column='_attr_str_', value=list(dfmerged.index))\n",
    "assert(all(dfmerged.index == dfmerged._attr_str_))\n",
    "\n",
    "d = {k:v for k, v in dfmerged.groupby(['__input_id__', '_attr_str_'])}\n",
    "\n",
    "in_attr_dfs = []\n",
    "for df in d.values():\n",
    "    assert(df.shape[0] == 3)\n",
    "    tmp = df.copy()\n",
    "    tmp.__count__ = sum(tmp.__count__)\n",
    "    tmp.drop_duplicates(inplace=True)\n",
    "    assert(tmp.shape[0] == 1)\n",
    "    in_attr_dfs.append(tmp)\n",
    "    \n",
    "input_attr_df = pd.concat(in_attr_dfs)\n",
    "input_attr_df.sort_values(by=['__input_id__', '__count__'], ascending=[True, False], inplace=True)\n",
    "assert(len(input_attr_df.index) == len(set(input_attr_df.index)))\n",
    "assert(all(input_attr_df.index == input_attr_df._attr_str_))\n",
    "input_attr_df.drop(columns='_attr_str_', inplace=True)\n",
    "\n",
    "if context == 'BP':\n",
    "    assert(all(input_attr_df.BRAIN_PARENCHYMA.astype(bool)))\n",
    "elif context == 'PS':\n",
    "    assert(all(input_attr_df.PERIVASCULAR_SPACE.astype(bool)))\n",
    "elif context == 'WM':\n",
    "    assert(all(input_attr_df.WHITE_MATTER_TRACT.astype(bool)))\n",
    "else:\n",
    "    # Unexpected!\n",
    "    assert(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attractor Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_to_func_str, _ = dml.read_boolean_functions(bnfuncsfile)\n",
    "bool_funcs = {k : dml.get_boolean_function(v) for (k,v) in node_to_func_str.items()}\n",
    "#len([(len(v) if (type(v) is list) else 1) for k,v in tmp.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = input_attr_df.drop(columns=['__input_id__', '__count__']).copy()\n",
    "false_attractor_indices = []\n",
    "\n",
    "for i in range(tmp.shape[0]):\n",
    "    print(str(i) + \" \", end='')\n",
    "    if (i+1 % 40) == 0: print(\"\\n\", end='')\n",
    "    if any(pd.isna(tmp.iloc[i, :])): continue\n",
    "    if not dml.is_attractor_state(state=tmp.iloc[i, :], inputs=tmp.iloc[i, :8], \n",
    "                                  bool_funcs=bool_funcs, n_steps=10000):\n",
    "        false_attractor_indices.append(i)\n",
    "\n",
    "assert(not false_attractor_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess Phenotype Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phenotype_table(uniq_attr_df):\n",
    "    tmp = uniq_attr_df.copy()\n",
    "    tmp['Dormant'] = np.nan\n",
    "    for attr in tmp.index:\n",
    "        cyc = tmp.loc[attr, 'Cell_Cycle']\n",
    "        mot = tmp.loc[attr, 'Directed_Motility']\n",
    "        apo = tmp.loc[attr, 'Apoptosis']\n",
    "        if np.isnan(cyc) or np.isnan(mot) or np.isnan(apo):\n",
    "            continue\n",
    "        cyc = bool(cyc)\n",
    "        mot = bool(mot)\n",
    "        apo = bool(apo)\n",
    "        tmp.loc[attr, 'Dormant'] = int((not cyc) and (not mot) and (not apo))\n",
    "\n",
    "    #var_set = ['Directed_Motility', 'Cell_Cycle', 'Apoptosis', 'Dormant', 'pOLIG2']\n",
    "    var_set = ['Directed_Motility', 'Cell_Cycle', 'Apoptosis', 'Dormant', 'pOLIG2', 'HIF', 'SMAD_2_3_4']\n",
    "    pw_counts = dml.get_pairwise_true_counts(tmp, var_set)\n",
    "    tmp = pw_counts.loc[var_set[:4], var_set[:4]].values\n",
    "    assert(np.count_nonzero(tmp - np.diag(np.diagonal(tmp))) == 0)\n",
    "    assert(pw_counts.loc['pOLIG2', 'Cell_Cycle'] == pw_counts.loc['pOLIG2', 'pOLIG2'])\n",
    "    \n",
    "    return pw_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = input_attr_df.drop(columns=['__input_id__', '__count__']).copy()\n",
    "assert(input_nodes == list(tmp.columns[:len(input_nodes)]))\n",
    "attr_nodes = sorted(list(set(tmp.columns) - set(input_nodes)))\n",
    "assert('_noinput_attr_id_' not in input_attr_df.columns)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "attr_df  = tmp.loc[:, attr_nodes].copy()\n",
    "attr_df.dropna(inplace=True)\n",
    "attr_id_strings = attr_df.apply(dml.binary_state_to_str, axis=1)\n",
    "attr_str_to_id = {attr_str : (attr_id + 1) \n",
    "                  for attr_id, attr_str in enumerate(sorted(attr_id_strings.unique()))}\n",
    "attr_df.insert(loc=0, column='_noinput_attr_id_', value=[attr_str_to_id[s]  for s in attr_id_strings])\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "uniq_attr_df = attr_df.copy()\n",
    "uniq_attr_df.drop_duplicates(inplace=True)\n",
    "uniq_attr_df.index = uniq_attr_df['_noinput_attr_id_'].values\n",
    "uniq_attr_df.sort_values(by='_noinput_attr_id_', inplace=True)\n",
    "uniq_attr_df = uniq_attr_df.astype(int)\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "get_phenotype_table(uniq_attr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_attr_df.to_pickle(path=input_to_attr_df_file)\n",
    "uniq_attr_df.to_pickle(path=uniq_attr_df_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Interactive Attractor Data Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i uniq_attr_df\n",
    "\n",
    "library(DT)\n",
    "\n",
    "DT::datatable(uniq_attr_df, rownames= TRUE, filter = 'top', class = 'cell-border stripe', \n",
    "              extensions = 'FixedHeader', \n",
    "              options = list(lengthMenu = c(64, 128, 256, 512), fixedHeader = TRUE)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i input_attr_df\n",
    "\n",
    "library(DT)\n",
    "\n",
    "DT::datatable(input_attr_df, rownames= FALSE, filter = 'top', class = 'cell-border stripe', \n",
    "              extensions = 'FixedHeader', \n",
    "              options = list(lengthMenu = c(64, 128, 256, 512), fixedHeader = TRUE)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Attractor Phenotype Distribution Summary Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = OrderedDict()\n",
    "d['Unperturbed'] = '_swarmout/gbmbnet_wm/uniq_attr_df.pkl'\n",
    "d['EGFR_0'] = '_swarmout/gbmbnet_wm_egfr_0/uniq_attr_df.pkl'\n",
    "d['SRC_0'] = '_swarmout/gbmbnet_wm_src_0/uniq_attr_df.pkl'\n",
    "d['MEK_0'] = '_swarmout/gbmbnet_wm_mek_0/uniq_attr_df.pkl'\n",
    "d['TFGBR_0'] = '_swarmout/gbmbnet_wm_tgfbr_0/uniq_attr_df.pkl'\n",
    "d['CK2_0'] = '_swarmout/gbmbnet_wm_ck2_0/uniq_attr_df.pkl'\n",
    "#d['MEK_TGFBR_0'] = '_swarmout/bnfuncs_5_mek_tgfbr_0/uniq_attr_df.pkl'\n",
    "#d['RAF_CK2_0'] = '_swarmout/bnfuncs_5_raf_ck2_0/uniq_attr_df.pkl'\n",
    "\n",
    "bnattr_pheno = pd.DataFrame(-1, index=d.keys(), \n",
    "    columns=['Go', 'Grow (w/o pOlig2)', 'Grow (pOlig2)', 'Apoptosis', 'Dormant']\n",
    ")\n",
    "\n",
    "for nw, path in d.items():\n",
    "    ptab = get_phenotype_table(pd.read_pickle(path))\n",
    "    pvec = pd.Series(np.diag(ptab), index=ptab.columns)\n",
    "    bnattr_pheno.loc[nw, 'Go'] = pvec['Directed_Motility']\n",
    "    bnattr_pheno.loc[nw, 'Grow (w/o pOlig2)'] = pvec['Cell_Cycle'] - pvec['pOLIG2']\n",
    "    bnattr_pheno.loc[nw, 'Grow (pOlig2)'] = pvec['pOLIG2']\n",
    "    bnattr_pheno.loc[nw, 'Apoptosis'] = pvec['Apoptosis']\n",
    "    bnattr_pheno.loc[nw, 'Dormant'] = pvec['Dormant']\n",
    "    \n",
    "bnattr_pheno_frac = bnattr_pheno.div(bnattr_pheno.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://benalexkeen.com/bar-charts-in-matplotlib/\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "barplot_bottoms = np.cumsum(bnattr_pheno_frac, axis=1)\n",
    "barplot_bottoms.insert(loc=0, column='tmp', value=0)\n",
    "barplot_bottoms = barplot_bottoms.iloc[:, :5]\n",
    "barplot_bottoms.columns = bnattr_pheno.columns\n",
    "\n",
    "iset = list(range(bnattr_pheno_frac.shape[0]))\n",
    "nwnames = list(bnattr_pheno_frac.index)\n",
    "colors = ['g', 'b', 'cyan', 'r', 'orange']\n",
    "\n",
    "for j, phtype in enumerate(bnattr_pheno_frac.columns):\n",
    "    plt.bar(iset, bnattr_pheno_frac[phtype], label=phtype, \n",
    "            color=colors[j], bottom=barplot_bottoms[phtype])\n",
    "\n",
    "plt.xticks(iset, nwnames)\n",
    "plt.ylabel(\"Cumulative Proportion\")\n",
    "plt.xlabel(\"Boolean Networks\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title(\"Attractor Phenotype Distribution\")\n",
    "plt.setp(plt.gca().get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Biowulf Swarm File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnfilepath = '_swarmout/gbmbnet_bp_alt/gbmbnet_bp.txt'\n",
    "N = 2**len(['EGF', 'PDGF', 'WNT_Canonical', 'TIMP', 'DNA_Damage', 'Ephrin_B1_B2', 'Oxygen'])\n",
    "filename = '_bnsim_bp.swarm'\n",
    "cmd = 'python swarm_bnsim_bp.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnfilepath = '_swarmout/gbmbnet_ps_alt/gbmbnet_ps.txt'\n",
    "N = 2**len(['EGF', 'PDGF', 'WNT_Canonical', 'TIMP', 'DNA_Damage', 'Ephrin_B1_B2'])\n",
    "filename = '_bnsim_ps.swarm'\n",
    "cmd = 'python swarm_bnsim_ps.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnfilepath = '_swarmout/gbmbnet_wm_alt/gbmbnet_wm.txt'\n",
    "N = 2**len(['EGF', 'PDGF', 'WNT_Canonical', 'TIMP', 'DNA_Damage', 'Ephrin_B1_B2', 'Oxygen'])\n",
    "filename = '_bnsim_wm.swarm'\n",
    "cmd = 'python swarm_bnsim_wm.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_indices = list(range(N))\n",
    "random_seeds = [1, 2, 3]\n",
    "num_init_conds = [3333, 3333, 3334]\n",
    "assert(len(random_seeds) == len(num_init_conds))\n",
    "\n",
    "with open(filename, 'wt') as f:\n",
    "    for i in input_indices:\n",
    "        for j, k in zip(random_seeds, num_init_conds):\n",
    "            ln = cmd + ' ' + str(i) + ' ' + str(j) + ' ' + str(k) + ' ' + bnfilepath\n",
    "            print(ln, file=f)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attractor to Expression Data Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_to_genes = dml.read_node_to_gene_symbols_file('./data/bnnode_to_gene_symbols_reka.txt')\n",
    "tmp_dict = dml.read_node_to_gene_symbols_file('./data/bnnode_to_gene_symbols.txt')\n",
    "for k, v in tmp_dict.items():\n",
    "    if k not in node_to_genes:\n",
    "        node_to_genes[k] = v\n",
    "        \n",
    "ivygap = pd.read_pickle('inst/rawdata/compare_w_expdata/ivygap.pkl')\n",
    "ivygap_exp = ivygap['exp']\n",
    "ivygap_samples = ivygap['samples']\n",
    "\n",
    "ivygap_node_exp = dml.get_boolnet_node_expression(ivygap_exp, node_to_genes).dropna().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color by Stem Status.\n",
    "ivygap_samples_colors = pd.Series('black', index=ivygap_samples.index)\n",
    "ivygap_samples_colors[ivygap_samples['stem_cluster_status'] == 'Stem Cluster'] = 'red'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivygap_samples_colors = pd.Series('yellow', index=ivygap_samples.index) # Cellular Tumor\n",
    "ivygap_samples_colors[ivygap_samples['location'] == 'Pseudopalisading Cells'] = 'red'\n",
    "ivygap_samples_colors[ivygap_samples['location'] == 'Microvascular Proliferation'] = 'green'\n",
    "ivygap_samples_colors[ivygap_samples['location'] == 'Perinecrotic Zone'] = 'cyan'\n",
    "ivygap_samples_colors[ivygap_samples['location'] == 'Infiltrating Tumor'] = 'magenta'\n",
    "ivygap_samples_colors[ivygap_samples['location'] == 'Hyperplastic Blood Vessels'] = 'orange'\n",
    "ivygap_samples_colors[ivygap_samples['location'] == 'Leading Edge'] = 'blue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "assert(ivygap_node_exp.index is ivygap_samples_colors.index)\n",
    "cmout_ivygap_nodexp = sns.clustermap(ivygap_node_exp, metric='euclidean', cmap='RdBu_r',\n",
    "    method='complete', row_colors=ivygap_samples_colors, figsize=(20,12))\n",
    "\n",
    "row_reord = ivygap_node_exp.index[cmout_ivygap_nodexp.dendrogram_row.reordered_ind]\n",
    "col_reord = ivygap_node_exp.columns[cmout_ivygap_nodexp.dendrogram_col.reordered_ind]\n",
    "ivygap_node_exp_reord = ivygap_node_exp.loc[row_reord, col_reord].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from plotly.tools import set_credentials_file\n",
    "\n",
    "set_credentials_file(username='vinodh.rajapakse', api_key='mQXgwB5B19HPXfbq2cvt')\n",
    "\n",
    "trace = go.Heatmap(z=ivygap_node_exp_reord.values[::-1, :],\n",
    "                   x=col_reord)\n",
    "data=[trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    autosize=False,\n",
    "    width=1400,\n",
    "    height=800\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='labelled-heatmap')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Stable Motifs Code (Locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to Boolean functions file (extracted from above PathVisio file).\n",
    "boolean_functions_path = \"./models/gbm_bnfuncs_2.txt\"\n",
    "\n",
    "# Path to Albert et al. stable motif (boolean network attractor) analysis code.\n",
    "stable_motifs_lib_path = \"/Users/rajapaksevn/repos/gbm_motility/lib/StableMotifs/dist/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_func_strings, _ = dml.read_boolean_functions(boolean_functions_path)\n",
    "inputs = ['EGF', 'PDGF', 'WNT_Canonical', 'TIMP', 'DNA_Damage', 'Ephrin_B1_B2', 'Oxygen']\n",
    "\n",
    "input_attr_df = dml.run_stable_motifs_for_input_combinations(inputs, bool_func_strings, stable_motifs_lib_path, \n",
    "                                                   timeout=300, output_file='bn_test_df_2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate Input/Attractor Table by Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_to_func_str, _ = dml.read_boolean_functions(bnfuncsfile)\n",
    "bool_funcs = {k : dml.get_boolean_function(v) for (k,v) in node_to_func_str.items()}\n",
    "\n",
    "node_list = input_nodes + sorted(list(set(bool_funcs.keys()) - set(input_nodes)))\n",
    "\n",
    "np.random.seed(13)\n",
    "start = timer()\n",
    "input_attr_df = dml.get_simulation_based_input_attractor_tab(\n",
    "    inputs=dml.get_state_table(pd.Series(np.nan, index=input_nodes)).iloc[:2,:], \n",
    "    nodes=node_list, \n",
    "    bool_funcs=bool_funcs, \n",
    "    n_steps=10000, \n",
    "    n_for_steady_state=5000, \n",
    "    n_init_conds=4, \n",
    "    synch_update=False, \n",
    "    outfile_root=None, \n",
    "    verbose=True)\n",
    "end = timer()\n",
    "\n",
    "print(\"\\nElapsed Time: \" + str(np.round(end - start, decimals=2)) + ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_state = pd.Series(np.nan, index=node_list)\n",
    "start_state[input_nodes] = input_attr_df.iloc[100, :8]\n",
    "start_state[non_input_nodes] = np.random.randint(low=0, high=2, size=len(non_input_nodes))\n",
    "\n",
    "profiler = Profiler()\n",
    "profiler.start()\n",
    "traj = dml.get_boolnet_trajectory(init_state=start_state, inputs=start_state[input_nodes], \n",
    "                                  bool_funcs=bool_funcs, n_steps=10000, synch_update=False)\n",
    "profiler.stop()\n",
    "print(profiler.output_text(color=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Symbolic Link (ARG1:SOURCE ARG2:LINK, RESULT: LINK --> SOURCE)\n",
    "ln -s /local/data/rajapaksevn/ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dynml as dml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "input_index = 1\n",
    "rseed = 13\n",
    "boolean_functions_path = \"_swarmout/bnfuncs_6/gbm_bnfuncs_6.txt\"\n",
    "nsteps = 1000\n",
    "synch_update = False\n",
    "\n",
    "node_to_func_str, _ = dml.read_boolean_functions(boolean_functions_path)\n",
    "bool_funcs = {k : dml.get_boolean_function(v) for (k,v) in node_to_func_str.items()}\n",
    "\n",
    "input_nodes = ['EGF', 'PDGF', 'WNT_Canonical', 'TIMP', 'ECM_Migratory_Stimuli', 'Oxygen', 'Physical_Barrier', 'Bradykinin']\n",
    "non_input_nodes = sorted(list(set(bool_funcs.keys()) - set(input_nodes)))\n",
    "node_list = input_nodes + non_input_nodes\n",
    "input_tab = dml.get_state_table(pd.Series(np.nan, index=input_nodes))\n",
    "\n",
    "start_state = pd.Series(np.nan, index=node_list)\n",
    "start_state[input_nodes] = input_tab.iloc[input_index, :]\n",
    "\n",
    "np.random.seed(rseed)\n",
    "start_state[non_input_nodes] = np.random.randint(low=0, high=2, size=len(non_input_nodes))\n",
    "np.random.seed(rseed+1)\n",
    "traj = dml.get_boolnet_trajectory(init_state=start_state, inputs=start_state[input_nodes], \n",
    "    bool_funcs=bool_funcs, n_steps=nsteps, synch_update=synch_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
